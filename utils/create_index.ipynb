{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "if load_dotenv():\n",
    "    print(\"Found Azure OpenAI API Base Endpoint: \" + os.getenv(\"AZURE_OPENAI_ENDPOINT\"))\n",
    "else: \n",
    "    print(\"Azure OpenAI API Base Endpoint not found. Have you configured the .env file?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "from azure.search.documents.indexes.models import (\n",
    "    SimpleField,\n",
    "    SearchFieldDataType,\n",
    "    SearchableField,\n",
    "    SearchField,\n",
    "    VectorSearch,\n",
    "    HnswAlgorithmConfiguration,\n",
    "    VectorSearchProfile,\n",
    "    SemanticConfiguration,\n",
    "    SemanticPrioritizedFields,\n",
    "    SemanticField,\n",
    "    SemanticSearch,\n",
    "    SearchIndex\n",
    "\n",
    ")\n",
    "\n",
    "credential = AzureKeyCredential(os.environ[\"AZURE_AI_SEARCH_KEY\"]) if len(os.environ[\"AZURE_AI_SEARCH_KEY\"]) > 0 else DefaultAzureCredential()\n",
    "\n",
    "index_name = \"products\"\n",
    "\n",
    "index_client = SearchIndexClient(\n",
    "    endpoint=os.environ[\"AZURE_AI_SEARCH_ENDPOINT\"], \n",
    "    credential=credential\n",
    ")\n",
    "\n",
    "# Create a search index with the fields and a vector field which we will fill with a vector based on the overview field\n",
    "fields = [\n",
    "    SimpleField(name=\"id\", type=SearchFieldDataType.String, key=True, sortable=True),\n",
    "    SearchableField(name=\"name\", type=SearchFieldDataType.String),\n",
    "    SearchableField(name=\"category\", type=SearchFieldDataType.String),\n",
    "    SearchableField(name=\"price\", type=SearchFieldDataType.String, sortable=True),\n",
    "    SearchableField(name=\"imageUrl\", type=SearchFieldDataType.String),\n",
    "    SearchableField(name=\"stars\", type=SearchFieldDataType.String),\n",
    "    SearchableField(name=\"description\", type=SearchFieldDataType.String, analyzer_name=\"en.lucene\"),\n",
    "    SearchField(name=\"vector\", type=SearchFieldDataType.Collection(SearchFieldDataType.Single),\n",
    "                searchable=True, vector_search_dimensions=1536, vector_search_profile_name=\"myHnswProfile\"),\n",
    "]\n",
    "\n",
    "#category_name,asin,title,imgUrl,productURL,stars,reviews,price,listPrice,category_id,isBestSeller,boughtInLastMonth,description\n",
    "\n",
    "# Configure the vector search configuration  \n",
    "vector_search = VectorSearch(\n",
    "    algorithms=[\n",
    "        HnswAlgorithmConfiguration(\n",
    "            name=\"myHnsw\"\n",
    "        )\n",
    "    ],\n",
    "    profiles=[\n",
    "        VectorSearchProfile(\n",
    "            name=\"myHnswProfile\",\n",
    "            algorithm_configuration_name=\"myHnsw\",\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Configure the semantic search configuration to prefer title and tagline fields over overview\n",
    "semantic_config = SemanticConfiguration(\n",
    "    name=\"products-semantic-config\",\n",
    "    prioritized_fields=SemanticPrioritizedFields(\n",
    "        title_field=SemanticField(field_name=\"name\"),\n",
    "        keywords_fields=[SemanticField(field_name=\"category\")],\n",
    "        content_fields=[SemanticField(field_name=\"description\")]\n",
    "    )\n",
    ")\n",
    "\n",
    "# Create the semantic settings with the configuration\n",
    "semantic_search = SemanticSearch(configurations=[semantic_config])\n",
    "\n",
    "# Create the search index with the semantic settings\n",
    "index = SearchIndex(name=index_name, fields=fields,\n",
    "                    vector_search=vector_search, semantic_search=semantic_search)\n",
    "result = index_client.create_or_update_index(index)\n",
    "print(f' {result.name} created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import AzureOpenAI\n",
    "from azure.search.documents import SearchClient\n",
    "client = AzureOpenAI(\n",
    "        api_key = os.getenv(\"AZURE_OPENAI_API_KEY\"),  \n",
    "        api_version = os.getenv(\"AZURE_OPENAI_VERSION\"),\n",
    "        azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "    )\n",
    "\n",
    "embedding_model = os.getenv(\"AZURE_OPENAI_EMBEDDING_MODEL\")\n",
    "\n",
    "# use an embeddingsmodel to create embeddings\n",
    "def get_embedding(text, model=embedding_model):\n",
    "    return client.embeddings.create(input = [text], model=model).data[0].embedding\n",
    "\n",
    "# 1. define function to parse csv row and create embedding for overview text\n",
    "def parseProduct(df, ind):\n",
    "    return dict([\n",
    "        (\"id\", str(df['asin'][ind])),\n",
    "        (\"category\", str(df['category_name'][ind])),\n",
    "        (\"name\", str(df['title'][ind])),\n",
    "        (\"price\", str(df['price'][ind])),\n",
    "        (\"stars\", str(df['stars'][ind])),\n",
    "        (\"imageUrl\", str(df['imgUrl'][ind])),\n",
    "        (\"description\", str(df['description'][ind])),\n",
    "        (\"vector\", get_embedding(str(df['description'][ind])))\n",
    "    ])\n",
    "\n",
    "# 2. load products from json\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "search_client = SearchClient(\n",
    "    endpoint=os.environ[\"AZURE_AI_SEARCH_ENDPOINT\"], \n",
    "    index_name=index_name,\n",
    "    credential=credential\n",
    ")\n",
    "\n",
    "## open all csv files in the data directory\n",
    "from pathlib import Path\n",
    "directory = '../data'\n",
    "\n",
    "files = Path(directory).glob('filtered_*.csv')\n",
    "for file in files:\n",
    "    print(file)\n",
    "    products = []\n",
    "    products_df = pd.read_csv(file)\n",
    "    products_df.info()\n",
    "    line_count = 0\n",
    "    for ind in products_df.index:\n",
    "        productEmbedding = parseProduct(products_df, ind)\n",
    "        products.append(productEmbedding)\n",
    "        line_count += 1\n",
    "        # print(productEmbedding)\n",
    "    print(f'Processed {line_count} lines.')\n",
    "    print('Loaded %s products.' % len(products))\n",
    "\n",
    "    # 3. upload documents to vector store\n",
    "    result = search_client.upload_documents(products)\n",
    "    print(f\"Successfully loaded {len(products)} products into Azure AI Search index.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI\n",
    "from azure.search.documents.models import (\n",
    "    VectorizedQuery\n",
    ")\n",
    "\n",
    "client = AzureOpenAI(\n",
    "        api_key = os.getenv(\"AZURE_OPENAI_API_KEY\"),  \n",
    "        api_version = os.getenv(\"AZURE_OPENAI_VERSION\"),\n",
    "        azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "    )\n",
    "\n",
    "deployment_name = os.getenv(\"AZURE_OPENAI_COMPLETION_DEPLOYMENT_NAME\")\n",
    "model_name = os.getenv(\"AZURE_OPENAI_COMPLETION_MODEL\")\n",
    "\n",
    "index_client = SearchClient(\n",
    "    endpoint=os.environ[\"AZURE_AI_SEARCH_ENDPOINT\"], \n",
    "    index_name=index_name,\n",
    "    credential=credential\n",
    ")\n",
    "\n",
    "question = \"Tell me about the latest Product. When was it released?\"\n",
    "\n",
    "# create a vectorized query based on the question\n",
    "vector = VectorizedQuery(vector=get_embedding(question), k_nearest_neighbors=5, fields=\"vector\")\n",
    "\n",
    "\n",
    "# create search client to retrieve products from the vector store\n",
    "found_docs = list(search_client.search(\n",
    "    search_text=None,\n",
    "    query_type=\"semantic\",\n",
    "    semantic_configuration_name=\"products-semantic-config\",\n",
    "    vector_queries=[vector],\n",
    "    select=[\"name\", \"category\", \"description\"],\n",
    "    top=5\n",
    "))\n",
    "\n",
    "# print the found documents and the field that were selected\n",
    "found_docs_as_text = \" \"\n",
    "for doc in enumerate(found_docs, start=1):    \n",
    "    print(\"Name: {}\".format(doc[\"name\"]))\n",
    "    print(\"Category: {}\".format(doc[\"category\"]))\n",
    "    print(\"----------\")\n",
    "\n",
    "    found_docs_as_text += \" \"+ \"Name: {}\".format(doc[\"name\"]) +\" \"+ \"Description: {}\".format(doc[\"description\"])\n",
    "\n",
    "# augment the question with the found documents and ask the LLM to generate a response\n",
    "system_prompt = \"You are an assistant to the user, you are given some context below, please answer the query of the user with as detail as possible\"\n",
    "\n",
    "parameters = [system_prompt, ' Context:', found_docs_as_text , ' Question:', question]\n",
    "joined_parameters = ''.join(parameters)\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "        model = deployment_name,\n",
    "        messages = [{\"role\" : \"assistant\", \"content\" : joined_parameters}],\n",
    "    )\n",
    "\n",
    "print (response.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "navigator",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
